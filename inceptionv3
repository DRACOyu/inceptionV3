"""Train a DeepLab v3 plus model using tf.estimator API."""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import argparse
import os
import sys

import tensorflow as tf
# import tensorflow.contrib.slim.python.slim.nets.inception_v3 as inception_v3
from inception_v3 import *

os.environ["CUDA_VISIBLE_DEVICES"] = "4,5"

parser = argparse.ArgumentParser()
parser.add_argument('--model_dir', type=str, default='./model_reid-ft-3',
                    help='Base directory for the model.')

parser.add_argument('--train_epochs', type=int, default=26,
                    help='Number of training epochs: '
                         'For 30K iteration with batch size 6, train_epoch = 17.01 (= 30K * 6 / 10,582). '
                         'For 30K iteration with batch size 8, train_epoch = 22.68 (= 30K * 8 / 10,582). '
                         'For 30K iteration with batch size 10, train_epoch = 25.52 (= 30K * 10 / 10,582). '
                         'For 30K iteration with batch size 11, train_epoch = 31.19 (= 30K * 11 / 10,582). '
                         'For 30K iteration with batch size 15, train_epoch = 42.53 (= 30K * 15 / 10,582). '
                         'For 30K iteration with batch size 16, train_epoch = 45.36 (= 30K * 16 / 10,582).')

parser.add_argument('--epochs_per_eval', type=int, default=1,
                    help='The number of training epochs to run between evaluations.')

parser.add_argument('--batch_size', type=int, default=64,
                    help='Number of examples per batch.')

parser.add_argument('--reid_data_dir', type=str, default='/root/data/MSMT17_V1/record/',
                    help='Path to the directory containing the PASCAL VOC data tf record.')

parser.add_argument('--pre_trained_model', type=str, default='/yzc/test/tensorflow-inceptionv3-reid-9/models/reid-9-imageft/model_ckpt-28w+.ckpt',
                    help='Path to the pre-trained model checkpoint.')

parser.add_argument('--initial_global_step', type=int, default=286003,
                    help='Initial global step for controlling learning rate when fine-tuning model.')

_HEIGHT = 512
_WIDTH = 170
_DEPTH = 3

num = 1041

def deeplabv3_plus_model_fn(features, labels, mode, params):

  labels_reid = labels
  pre_trained_model = params['pre_trained_model']
  is_training = True
  with tf.contrib.slim.arg_scope(inception_v3_arg_scope()):
      logits_reid, end_points = inception_v3(features,
                                             num_classes=num,
                                             is_training=is_training,
                                             global_pool=False)

  # if is_training:
  #     exclude = ['InceptionV3/Logits']
  #     variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=exclude)
  #     tf.train.init_from_checkpoint(pre_trained_model,
  #                                   {v.name.split(':')[0]: v for v in variables_to_restore})

  tf.losses.softmax_cross_entropy(onehot_labels=labels_reid, logits=logits_reid)  # 添加交叉熵损失loss=1.6
  loss_reid = tf.losses.get_total_loss(add_regularization_losses=True)  # 添加正则化损失loss=2.2



  predictions = {
      'probabilities': tf.nn.softmax(logits_reid, name='softmax_tensor')
  }

  accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits_reid, 1), tf.argmax(labels_reid, 1)), tf.float32))

  tf.identity(accuracy, name='accuracy')
  tf.summary.scalar('accuracy', accuracy)

  tf.identity(loss_reid, name='loss_reid')
  tf.summary.scalar('loss_reid', loss_reid)

  if mode == tf.estimator.ModeKeys.TRAIN:
    global_step = tf.train.get_or_create_global_step()

    base_lr=0.01

    global_step_ = tf.cast(global_step, tf.int32)-params['initial_global_step']
    learning_rate = tf.train.exponential_decay(base_lr, global_step_, 5000, 0.95)

    tf.identity(learning_rate, name='learning_rate')
    tf.summary.scalar('learning_rate', learning_rate)

    tf.identity(global_step_, name='global_step_')
    tf.summary.scalar('global_step_', global_step_)

    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)

    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
    with tf.control_dependencies(update_ops):
      train_op = slim.learning.create_train_op(total_loss=loss_reid, optimizer=optimizer)
  else:
    train_op = None

  labels_reid =tf.cast(labels_reid,tf.int64)
  acc3= tf.metrics.precision_at_k(labels_reid,logits_reid,num)
  labels_reid =tf.cast(labels_reid,tf.float32)
  acc2 = tf.metrics.mean_squared_error(labels_reid,logits_reid)


  eval_metric_ops = {"acc2":acc2,"acc3":acc3}

  return tf.estimator.EstimatorSpec(
      mode=mode,
      predictions=predictions,
      loss=loss_reid,
      train_op=train_op,
      eval_metric_ops=eval_metric_ops)

def get_filenames_reid(is_training, data_dir):
  """Return a list of filenames.

  Args:
    is_training: A boolean denoting whether the input is for training.
    data_dir: path to the the directory containing the input data.

  Returns:
    A list of file names.
  """
  if is_training:
    return [os.path.join(data_dir, 'train-512-170.tfrecords')]
  else:
    return [os.path.join(data_dir, 'val-512-170.tfrecords')]

def parse_record_reid(raw_record):
  """Parse PASCAL image and label from a tf record."""
  keys_to_features = {
      'image_raw': tf.FixedLenFeature([], tf.string),
      'height': tf.FixedLenFeature([], tf.int64),
      'width': tf.FixedLenFeature([], tf.int64),
      'depth': tf.FixedLenFeature([], tf.int64),
      'label': tf.FixedLenFeature([], tf.int64)
  }
  parsed = tf.parse_single_example(raw_record, keys_to_features)
  # image = tf.image.decode_image(
  #     tf.reshape(parsed['image_raw'], shape=[]), _DEPTH)

  image = tf.decode_raw(parsed['image_raw'], tf.uint8)
  image = tf.to_float(tf.image.convert_image_dtype(image, dtype=tf.uint8))
  image = tf.reshape(image, [_HEIGHT, _WIDTH, 3])
  image = tf.cast(image, tf.float32) * (1. / 255.0)

  label = tf.cast(parsed['label'],tf.int32)

  label = tf.one_hot(label, num, 1, 0)
  # labels={"seg":None,"reid":label}
  return image, label

def input_fn(is_training, reid_data_dir, batch_size=16, num_epochs=1):
  """Input_fn using the tf.data input pipeline for CIFAR-10 dataset.

  Args:
    is_training: A boolean denoting whether the input is for training.
    data_dir: The directory containing the input data.
    batch_size: The number of samples per batch.
    num_epochs: The number of epochs to repeat the dataset.

  Returns:
    A tuple of images and labels.
  """
  # dataset = tf.data.Dataset.from_tensor_slices(get_filenames(is_training, data_dir))
  # dataset_seg = dataset.flat_map(tf.data.TFRecordDataset)

  dataset_reid = tf.data.Dataset.from_tensor_slices(get_filenames_reid(is_training, reid_data_dir))
  dataset_reid = dataset_reid.flat_map(tf.data.TFRecordDataset)

  if is_training:
    # When choosing shuffle buffer sizes, larger sizes result in better
    # randomness, while smaller sizes have better performance.
    # is a relatively small dataset, we choose to shuffle the full epoch.
    dataset_reid = dataset_reid.shuffle(buffer_size=30248)

  dataset_reid = dataset_reid.map(parse_record_reid)
  dataset_reid = dataset_reid.prefetch(batch_size)
  dataset_reid = dataset_reid.repeat(num_epochs)
  dataset_reid = dataset_reid.batch(batch_size)

  iterator = dataset_reid.make_one_shot_iterator()
  images_reid, label_reid = iterator.get_next()

  return images_reid, label_reid

def main(unused_argv):

  run_config = tf.estimator.RunConfig().replace(save_checkpoints_secs=1e9)
  model = tf.estimator.Estimator(
      model_fn=deeplabv3_plus_model_fn,
      model_dir=FLAGS.model_dir,
      config=run_config,
      params={
          'batch_size': FLAGS.batch_size,
          'pre_trained_model': FLAGS.pre_trained_model,
          'initial_global_step': FLAGS.initial_global_step
      })

  for _ in range(FLAGS.train_epochs // FLAGS.epochs_per_eval):
    tensors_to_log = {
      'step': 'global_step_',
      'learning_rate': 'learning_rate',
      'loss_reid': 'loss_reid',
     'accuracy': 'accuracy'
    }

    logging_hook = tf.train.LoggingTensorHook(
        tensors=tensors_to_log, every_n_iter=10)
    train_hooks = [logging_hook]
    eval_hooks = None

    # if FLAGS.debug:
    #   debug_hook = tf_debug.LocalCLIDebugHook()
    #   train_hooks.append(debug_hook)
    #   eval_hooks = [debug_hook]

    tf.logging.info("Start training.")
    model.train(
        input_fn=lambda: input_fn(True, FLAGS.reid_data_dir, FLAGS.epochs_per_eval),
        hooks=train_hooks,
        # steps=1  # For debug
    )
    #
    # tf.logging.info("Start evaluation.")
    # # Evaluate the model and print results
    # eval_results = model.evaluate(
    #     # Batch size must be 1 for testing because the images' size differs
    #     input_fn=lambda: input_fn(False, FLAGS.reid_data_dir,1),
    #     hooks=eval_hooks,
    #     # steps=1  # For debug
    # )
    # print(eval_results)


if __name__ == '__main__':
  tf.reset_default_graph()
  tf.logging.set_verbosity(tf.logging.INFO)
  FLAGS, unparsed = parser.parse_known_args()
  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)

